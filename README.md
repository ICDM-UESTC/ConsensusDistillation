# Consensus-Driven Distillation for Trustworthy Explanations in Self-Interpretable GNNs

**ğŸ’» Official implementation of our TPAMI submission (extension of ICML 2025): Consensus-Driven Distillation for Trustworthy Explanations in Self-Interpretable GNNs**

> ğŸ§  Authors: [Wenxin Tai](https://scholar.google.com/citations?user=YyxocAIAAAAJ&hl=en), [Fan Zhou](https://scholar.google.com/citations?user=Ihj2Rw8AAAAJ&hl=en), [Ting Zhong](https://scholar.google.com/citations?user=Mdr0XDkAAAAJ&hl=en), [Goce Trajcevski](https://scholar.google.com/citations?user=Avus2kcAAAAJ&hl=en), [Kunpeng Zhang](https://scholar.google.com/citations?user=rnpemAoAAAAJ&hl=en&oi=ao), [Jing Gao](https://scholar.google.com/citations?user=Ftj1h4cAAAAJ&hl=en&oi=ao), [Philip S. Yu](https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=en&oi=ao)   
> ğŸ“ Institutions: University of Electronic Science and Technology of China & Iowa State University & University of Maryland, College Park & Purdue University & University of Illinois, Chicago.  
> ğŸ”— [Paper Link](https://icml.cc/virtual/2025/poster/44426)
> ğŸ¤– This repository is maintained by [ICDM Lab](https://www.icdmlab.com/)

---

## ğŸ§© Overview

<p align="center">
  <img src="assets/intro.png" width="100%" />
</p>

**TL;DR: Our ICML paper proposed Explanation Ensemble (EE), which improves the trustworthiness of SI-GNNs by aggregating multiple explanations from independently trained models. While effective, it has high computational cost during inference (limits its deployment) and is incompatible with single-explanation metrics such as FID (limits its evaluation). In this extension, we propose Consensus Distillation (CD), which distills the ensembleâ€™s consensus knowledge into a single model, retaining EEâ€™s capability while addressing its limitations.

---

## ğŸ“¦ Repository Structure

```bash
â”œâ”€â”€ assets
â”œâ”€â”€ configs         # configuration
â”œâ”€â”€ criterion.py    # loss function
â”œâ”€â”€ dataloader.py   # load data
â”œâ”€â”€ dataset.py      # process data
â”œâ”€â”€ datasets        # raw dataset
â”œâ”€â”€ explainer.py    # explainer in self-interpretable GNNs (MLP)
â”œâ”€â”€ main.py         # entry
â”œâ”€â”€ model.py        # GNN backbone (GIN/GCN)
â”œâ”€â”€ outputs         # checkpoints/logs
â”œâ”€â”€ README.md
â”œâ”€â”€ run.sh 
â””â”€â”€ trainer.py      # train/valid/test
````

---

## âš™ï¸ Installation

We recommend creating a fresh Python environment (e.g., with conda):

```bash
conda create -n exgnn python=3.9
conda activate exgnn
pip install -r requirements.txt
```

---

## ğŸ“š Datasets

We evaluate our method on a variety of datasets:

* Synthetic: BA-2MOTIFS
* Molecular: MUTAGENICITY, 3MR, BENZENE

Datasets can be downloaded from [Google Drive](https://drive.google.com/drive/folders/1RaOKbWABerHfea_sJZGIbXSy0FcOzK0O?usp=sharing), place all datasets (e.g., `ba_2motifs`, `benzene`, `mr`, `mutag`) in the `datasets/` folder.

---

## ğŸƒâ€â™€ï¸ Quick Start

### 1. Train self-interpretable GNNs 

```bash
python main.py --run_time 10 --dataset ba_2motifs --method gsat_cd
```


### 2. Evaluate redundancy (SHD and AUC)

```bash
python main.py --run_time 10 --dataset ba_2motifs --method gsat_cd --calculate_shd
```

```bash
python main.py --run_time 10 --dataset ba_2motifs --method gsat_cd --test_by_sample_ensemble
```

---

## ğŸ“ Pretrained Checkpoints
We provide **pretrained model checkpoints** for quick evaluation and reproduction.  

You can download them from the [Releases](https://github.com/ICDM-UESTC/ConsensusDistillation/releases) tab

To use the checkpoint, place it in the `outputs/checkpoints/` folder and run:
```bash
python main.py --run_time 10 --dataset ba_2motifs --method gsat_cd --calculate_shd
python main.py --run_time 10 --dataset ba_2motifs --method gsat_cd --test_by_sample_ensemble
```

---

## ğŸ“Œ Citation

If you find this work useful, please cite us:

```bibtex
@inproceedings{tai2025redundancy,
  title     = {Redundancy Undermines the Trustworthiness of Self-Interpretable GNNs},
  author    = {Tai, Wenxin and Zhong, Ting and Trajcevski, Goce and Zhou, Fan},
  booktitle = {Proceedings of the 42nd International Conference on Machine Learning (ICML)},
  year      = {2025}
}
```

---

## ğŸ“¬ Contact

If you have questions or suggestions, feel free to reach out via GitHub Issues or email: wxtai [AT] outlook [DOT] com